{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "    go.mod\n",
      "    go.sum\n",
      "    README.md\n",
      "    package-lock.json\n",
      "    package.json\n",
      "    AIDevops.ipynb\n",
      "    dist/\n",
      "        schema.json\n",
      "    samples/\n",
      "        step-template.yaml\n",
      "        step.yaml\n",
      "        stage-group.yaml\n",
      "        step-approval.yaml\n",
      "        stage-runtime.yaml\n",
      "        failure-strategy-retry.yaml\n",
      "        step-background.yaml\n",
      "        pipeline-clone.yaml\n",
      "        step-run.yaml\n",
      "        pipeline-inputs.yaml\n",
      "        step-parallel.yaml\n",
      "        failure-strategy-manual.yaml\n",
      "        output.yaml\n",
      "        stage-template.yaml\n",
      "        step-run-test.yaml\n",
      "        matrix.yaml\n",
      "        step-queue.yaml\n",
      "        step-action.yaml\n",
      "        step-barrier.yaml\n",
      "        stage-volumes.yaml\n",
      "        pipeline-on.yaml\n",
      "        failure-strategy.yaml\n",
      "        pipeline-service.yaml\n",
      "        stage-caching.yaml\n",
      "        pipeline.yaml\n",
      "        stage-approval.yaml\n",
      "        environment.yaml\n",
      "        stage.yaml\n",
      "        step-group.yaml\n",
      "        stage-parallel.yaml\n",
      "        complex/\n",
      "            dynamic-provisioned-infra.yaml\n",
      "            kubernetes-canary.yaml\n",
      "            kubernetes-rolling.yaml\n",
      "            kubernetes-bluegreen.yaml\n",
      "            terraform-provisioning-adhoc.yaml\n",
      "        actions/\n",
      "            policy.yaml\n",
      "            wait.yaml\n",
      "            http.yaml\n",
      "            jira.yaml\n",
      "            helm-deploy.yaml\n",
      "            snow.yaml\n",
      "        templates/\n",
      "            npm.yaml\n",
      "    schema/\n",
      "        schema.ts\n",
      "        clone.ts\n",
      "        output.ts\n",
      "        status.ts\n",
      "        report.ts\n",
      "        repository.ts\n",
      "        workspace.ts\n",
      "        template.ts\n",
      "        permissions.ts\n",
      "        environment.ts\n",
      "        input.ts\n",
      "        pipeline.ts\n",
      "        failure.ts\n",
      "        platform.ts\n",
      "        container.ts\n",
      "        stages.ts\n",
      "        volumes.ts\n",
      "        runtime.ts\n",
      "        strategy.ts\n",
      "        cache.ts\n",
      "        concurrency.ts\n",
      "        on.ts\n",
      "        service.ts\n",
      "        steps.ts\n",
      "    approved/\n",
      "        k8s-delete.yaml\n",
      "        step.yaml\n",
      "        parallel-stage.yaml\n",
      "        kubernetes-blue-green.yaml\n",
      "        http.yaml\n",
      "        kubernetes-canary.yaml\n",
      "        wait-step.yaml\n",
      "        kubernetes-rolling.yaml\n",
      "        shell-script.yaml\n",
      "        matrix.yaml\n",
      "        failure-strategy.yaml\n",
      "        parallel-step.yaml\n",
      "        k8s-traffic-shift.yaml\n",
      "        pipeline.yaml\n",
      "        stage.yaml\n",
      "        step-group.yaml\n",
      "    scripts/\n",
      "        bundle.js\n",
      "        generate.js\n",
      "        generate2.js\n",
      "        document.js\n",
      "        templates/\n",
      "            enum.handlebars\n",
      "            custom_mount.handlebars\n",
      "            custom_action.handlebars\n",
      "            custom_volume.handlebars\n",
      "            parse.handlebars\n",
      "            custom_runtime.handlebars\n",
      "            custom_matrix.handlebars\n",
      "            struct_or_slice.handlebars\n",
      "            custom_on_schedule.handlebars\n",
      "            struct_or_string.handlebars\n",
      "            types.handlebars\n",
      "            custom_step.handlebars\n",
      "            custom_perms.handlebars\n",
      "            custom_environment.handlebars\n",
      "            custom_delegate.handlebars\n",
      "            struct.handlebars\n",
      "            parse_test.handlebars\n",
      "            custom_on.handlebars\n",
      "        helpers/\n",
      "            types.js\n",
      "    yaml/\n",
      "        volume_claim.go\n",
      "        step_queue.go\n",
      "        service_ref.go\n",
      "        credentials.go\n",
      "        environment_ref.go\n",
      "        clone_ref.go\n",
      "        service.go\n",
      "        strategy_matrix.go\n",
      "        runtime_vm.go\n",
      "        action.go\n",
      "        runtime.go\n",
      "        schema_infra.go\n",
      "        types.go\n",
      "        delegate.go\n",
      "        strategy.go\n",
      "        perms.go\n",
      "        stage_approval.go\n",
      "        stage_template.go\n",
      "        step_barrier.go\n",
      "        cache.go\n",
      "        environment_ref_item.go\n",
      "        parse_test.go\n",
      "        concurrency.go\n",
      "        action_type.go\n",
      "        on.go\n",
      "        runtime_cloud.go\n",
      "        environment_type.go\n",
      "        test_intelligence.go\n",
      "        template.go\n",
      "        environment.go\n",
      "        on_schedule.go\n",
      "        volume_bind.go\n",
      "        input.go\n",
      "        machine_size.go\n",
      "        pipeline.go\n",
      "        step_action.go\n",
      "        test_splitting.go\n",
      "        failure.go\n",
      "        action_retry.go\n",
      "        step_group.go\n",
      "        step.go\n",
      "        volume_temp.go\n",
      "        stage_group.go\n",
      "        runtime_kubernetes.go\n",
      "        volume.go\n",
      "        platform.go\n",
      "        report_list.go\n",
      "        container.go\n",
      "        failure_type.go\n",
      "        step_tester.go\n",
      "        schema.go\n",
      "        step_run.go\n",
      "        strategy_for.go\n",
      "        strategy_while.go\n",
      "        clone.go\n",
      "        status.go\n",
      "        machine_image.go\n",
      "        report.go\n",
      "        volume_config_map.go\n",
      "        action_manual.go\n",
      "        repository.go\n",
      "        step_approval.go\n",
      "        step_template.go\n",
      "        parse.go\n",
      "        workspace.go\n",
      "        stage.go\n",
      "        mount.go\n",
      "        credentials_aws.go\n",
      "        testdata/\n",
      "            sample.yaml.golden\n",
      "            sample.yaml\n",
      "        utils/\n",
      "            utils.go\n",
      "            expand/\n",
      "                expand_test.go\n",
      "                expand.go\n",
      "                testdata/\n",
      "                    step.yaml.golden\n",
      "                    step.yaml\n",
      "                    stage.yaml.golden\n",
      "                    stage.yaml\n",
      "                matrix/\n",
      "                    matrix.go\n",
      "            walk/\n",
      "                walk_test.go\n",
      "                walk.go\n",
      "            normalize/\n",
      "                namer_test.go\n",
      "                normalize.go\n",
      "                namer.go\n",
      "                normalize_test.go\n",
      "            github/\n",
      "                convert.go\n",
      "                convert_test.go\n",
      "            resolver/\n",
      "                resolver_test.go\n",
      "                resolver.go\n",
      "                testdata/\n",
      "                    step1.yaml.golden\n",
      "                    step2.yaml\n",
      "                    stage1.yaml.golden\n",
      "                    step2.yaml.golden\n",
      "                    stage1.yaml\n",
      "                    step1.yaml\n",
      "                    templates/\n",
      "                        golang.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        # Filter out directories and files starting with '.'\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        files = [f for f in files if not f.startswith('.')]\n",
    "        \n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "\n",
    "# Set the startpath to the current directory (repo root)\n",
    "startpath = '.'\n",
    "\n",
    "# Run the function\n",
    "list_files(startpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the OpenAI API key from environment variables\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "\n",
    "def gather_repo_context(folders):\n",
    "    context = \"\"\n",
    "    file_list = []\n",
    "    for folder in folders:\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            dirs[:] = [d for d in dirs if not d.startswith('.')]  # Exclude hidden directories\n",
    "            files = [f for f in files if not f.startswith('.')]  # Exclude hidden files\n",
    "            \n",
    "            for file in files:\n",
    "                if file.endswith(('.yaml', '.yml', '.ts', '.js', '.json', '.md', '.go')):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    file_list.append(file_path)\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        context += f\"\\n\\nFile: {file_path}\\n\" + f.read()\n",
    "    return context, file_list\n",
    "\n",
    "def create_messages(task, prompt, current_pipeline=None, logs=None, error_message=None, repo_context=\"\", secrets=None, user_info=None):\n",
    "    system_prompt = (\n",
    "        \"You are an AI programming assistant named 'AI Devops Engineer'. \"\n",
    "        \"You are part of a chat interface for an open source CI/CD platform called 'Gitness'. \"\n",
    "        \"Follow the user's requirements carefully & to the letter. \"\n",
    "        \"Your expertise is strictly limited to CI/CD and DevOps topics. \"\n",
    "        \"Follow Harness content policies. \"\n",
    "        \"Avoid content that violates copyrights. \"\n",
    "        \"For questions not related to CI/CD and DevOps, simply give a reminder that you are an AI Devops Engineer. \"\n",
    "        \"Keep your answers short and impersonal. \"\n",
    "        \"You can answer general DevOps questions and perform the following tasks through tool calls: \"\n",
    "        \"* Generate a CI/CD pipeline configuration \"\n",
    "        \"* Update a CI/CD pipeline configuration \"\n",
    "        \"* Analyze failed pipeline logs and suggest a code fix \"\n",
    "        \"First think step-by-step - describe your plan for what to build and then do it. \"\n",
    "        \"Minimize any other prose. \"\n",
    "        \"Avoid wrapping the whole response in triple backticks. \"\n",
    "        \"You can understand and use context from Gitness examples, JSON schema, and YAML files. \"\n",
    "        \"Each time you respond ensure the USER QUERY is satisfied to the best of your ability. \"\n",
    "        \"Make no assumptions about the functions and usage of YAML files that do not exist in the context, if there is missing information, ask for that information. \"\n",
    "        \"Do not make up an answer to questions that are not related to the query. \"\n",
    "        \"Prioritize using tool calls to perform the tasks when possible. \"\n",
    "        \"Do not explicitly mention the tool in the response. \"\n",
    "        \"There is no need to provide the full code or yaml in the message response unless specifically asked for. \"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"system\", \"content\": f\"Context from the repo: {repo_context}\"}\n",
    "    ]\n",
    "    \n",
    "    if secrets:\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"List of secrets: {secrets}\"})\n",
    "    \n",
    "    if user_info:\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"User information: {user_info}\"})\n",
    "    \n",
    "    if task == \"generate_pipeline\":\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    elif task == \"update_pipeline\":\n",
    "        if current_pipeline is None:\n",
    "            raise ValueError(\"current_pipeline must be provided for updating a pipeline.\")\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"The current pipeline configuration is:\\n{current_pipeline}\\n{prompt}\"})\n",
    "    elif task == \"fix_failed_pipeline\":\n",
    "        if logs is None or error_message is None:\n",
    "            raise ValueError(\"logs and error_message must be provided for analyzing a failed pipeline.\")\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"Analyze the following pipeline logs and error message to suggest a code fix:\\nLogs:\\n{logs}\\nError Message:\\n{error_message}\"})\n",
    "    else:\n",
    "        raise ValueError(\"Unknown task. Please provide a valid task: generate_pipeline, update_pipeline, or fix_failed_pipeline.\")\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def create_tools(task):\n",
    "    if task == \"generate_pipeline\":\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"generate_pipeline\",\n",
    "                    \"description\": \"Generates a CI/CD pipeline.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"pipeline_config\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The YAML configuration of the generated pipeline.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"pipeline_config\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    elif task == \"update_pipeline\":\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"update_pipeline\",\n",
    "                    \"description\": \"Updates a CI/CD pipeline\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"updated_pipeline_config\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The updated YAML configuration of the pipeline.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"updated_pipeline_config\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    elif task == \"fix_failed_pipeline\":\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"fix_failed_pipeline\",\n",
    "                    \"description\": \"Fix a failed pipeline.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"suggested_fix\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The suggested code fix based on the logs and error message.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"suggested_fix\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown task. Please provide a valid task: generate_pipeline, update_pipeline, or fix_failed_pipeline.\")\n",
    "    \n",
    "    return tools\n",
    "\n",
    "def call_openai_function(task, prompt, current_pipeline=None, logs=None, error_message=None, temperature=0.3, seed=42):\n",
    "    folders = ['./samples', './dist']  # List of folders to gather context from\n",
    "    repo_context, file_list = gather_repo_context(folders)\n",
    "\n",
    "    secrets = {\n",
    "        \"AWS_ACCESS_KEY_ID\": \"AKIA...\",\n",
    "        \"AWS_SECRET_ACCESS_KEY\": \"abc123...\",\n",
    "        \"DOCKER_PASSWORD\": \"s3cr3t...\"\n",
    "    }\n",
    "    \n",
    "    user_info = {\n",
    "        \"username\": \"johndoe\",\n",
    "        \"email\": \"johndoe@example.com\",\n",
    "        \"role\": \"developer\"\n",
    "    }\n",
    "    \n",
    "    messages = create_messages(task, prompt, current_pipeline, logs, error_message, repo_context, secrets, user_info)\n",
    "    tools = create_tools(task)\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        temperature=temperature,\n",
    "        user=\"userId\",  # https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids - not required, but recommended\n",
    "        seed=seed,\n",
    "        tool_choice=\"required\"\n",
    "\n",
    "    )\n",
    "\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            print(\"Made tool call:\")\n",
    "            print(f\"Tool Name: {tool_call.function.name}\")\n",
    "            print(f\"Arguments: {tool_call.function.arguments}\")\n",
    "    else:\n",
    "        print(\"No tool call made.\")\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made tool call:\n",
      "Tool Name: generate_pipeline\n",
      "Arguments: {\"pipeline_config\":\"pipeline:\\n  stages:\\n    - steps:\\n        - run:\\n            script: |\\n              python setup.py install\\n              python -m unittest discover\"}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Generate a CI/CD Pipeline Configuration\n",
    "task = \"generate_pipeline\"\n",
    "prompt = \"Build python build pipeline\"\n",
    "response = call_openai_function(task, prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made tool call:\n",
      "Tool Name: update_pipeline\n",
      "Arguments: {\"updated_pipeline_config\":\"pipeline:\\n  stages:\\n    - name: Lint\\n      steps:\\n        - name: Run Flake8\\n          image: python:3.8\\n          commands:\\n            - pip install flake8\\n            - flake8 .\\n    - name: Test\\n      steps:\\n        - name: Run Tests\\n          image: python:3.8\\n          commands:\\n            - pip install -r requirements.txt\\n            - pytest\\n    - name: Deploy\\n      steps:\\n        - name: Authenticate GCP\\n          image: google/cloud-sdk:latest\\n          commands:\\n            - echo $GOOGLE_APPLICATION_CREDENTIALS > /tmp/account.json\\n            - gcloud auth activate-service-account --key-file=/tmp/account.json\\n        - name: Deploy to GCP\\n          image: google/cloud-sdk:latest\\n          commands:\\n            - gcloud app deploy\"}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example 2: Update a CI/CD Pipeline Configuration\n",
    "task = \"update_pipeline\"\n",
    "current_pipeline = \"\"\"\n",
    "pipeline:\n",
    "  stages:\n",
    "    - name: Lint\n",
    "      steps:\n",
    "        - name: Run Flake8\n",
    "          image: python:3.8\n",
    "          commands:\n",
    "            - pip install flake8\n",
    "            - flake8 .\n",
    "    - name: Test\n",
    "      steps:\n",
    "        - name: Run Tests\n",
    "          image: python:3.8\n",
    "          commands:\n",
    "            - pip install -r requirements.txt\n",
    "            - pytest\n",
    "\"\"\"\n",
    "prompt = \"Add a stage for deploying to Google Cloud Platform (GCP) using the user's credentials. Update it for me.\"\n",
    "response = call_openai_function(task, prompt, current_pipeline=current_pipeline)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made tool call:\n",
      "Tool Name: fix_failed_pipeline\n",
      "Arguments: {\"suggested_fix\":\"Modify the 'environment' section to be a map instead of a sequence. Change:\\n  environment:\\n  - DOCKER_PASSWORD=${{ secrets.DOCKER_PASSWORD }}\\n  - DOCKER_USERNAME=${{ secrets.DOCKER_USERNAME }}\\nTo:\\n  environment:\\n    DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}\\n    DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}\"}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example 3: Analyze Failed Pipeline Logs and Suggest a Fix\n",
    "task = \"fix_failed_pipeline\"\n",
    "logs = \"\"\"\n",
    "Pipeline execution failed at stage 'Build'. Error parsing YAML configuration:\n",
    "- name: Build\n",
    "  steps:\n",
    "    - name: Build Image\n",
    "      image: docker:latest\n",
    "      commands:\n",
    "        - docker build -t my-app .\n",
    "        - docker push my-app:latest\n",
    "      environment:\n",
    "      - DOCKER_PASSWORD=${{ secrets.DOCKER_PASSWORD }}\n",
    "      - DOCKER_USERNAME=${{ secrets.DOCKER_USERNAME }}\n",
    "[ERROR] Invalid YAML format at line 6, column 7: 'environment' should be a map, but found a sequence instead.\n",
    "\"\"\"\n",
    "error_message = \"YAML configuration error: 'environment' should be a map, but found a sequence instead.\"\n",
    "\n",
    "response = call_openai_function(task, None, logs=logs, error_message=error_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start testing against HTTP endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 Response:\n",
      "{'response': {'content': \"I will create a CI/CD pipeline to build a Python project. The pipeline will include the necessary steps to install dependencies, run tests, and build the application. Here is the step-by-step plan:\\n\\n1. **Install dependencies**:\\n   - Typically, dependencies are listed in a `requirements.txt` or `Pipfile`.\\n2. **Run tests**:\\n   - Use a test framework like `unittest`, `pytest`, etc.\\n3. **Build the application**:\\n   - For Python, this may mean packaging the application for distribution.\\n\\nLet's proceed with creating the YAML configuration for this pipeline.\\n\\n```yaml\\npipeline:\\n  stages:\\n    - name: Install Dependencies\\n      steps:\\n        - run:\\n            script: |\\n              pip install -r requirements.txt\\n\\n    - name: Run Tests\\n      steps:\\n        - run:\\n            script: |\\n              pytest\\n\\n    - name: Build Package\\n      steps:\\n        - run:\\n            script: |\\n              python setup.py sdist\\n```\\n\\nLet's generate this pipeline.\", 'role': 'assistant', 'function_call': None, 'tool_calls': [{'id': 'call_YLdW5yZB2LGV0rclCunOFKM6', 'function': {'arguments': '{\"pipeline_config\":\"pipeline:\\\\n  stages:\\\\n    - name: Install Dependencies\\\\n      steps:\\\\n        - run:\\\\n            script: |\\\\n              pip install -r requirements.txt\\\\n\\\\n    - name: Run Tests\\\\n      steps:\\\\n        - run:\\\\n            script: |\\\\n              pytest\\\\n\\\\n    - name: Build Package\\\\n      steps:\\\\n        - run:\\\\n            script: |\\\\n              python setup.py sdist\"}', 'name': 'generate_pipeline'}, 'type': 'function'}]}}\n",
      "Example 2 Response:\n",
      "{'response': {'content': 'Plan:\\n1. Add a new stage named \"Deploy\" for GCP deployment.\\n2. Configure the step to authenticate using user-provided GCP credentials.\\n3. Add commands to deploy the application using `gcloud`.\\n\\nAdding the new stage to the pipeline:\\n\\n```yaml\\npipeline:\\n  stages:\\n    - name: Lint\\n      steps:\\n        - name: Run Flake8\\n          image: python:3.8\\n          commands:\\n            - pip install flake8\\n            - flake8 .\\n    - name: Test\\n      steps:\\n        - name: Run Tests\\n          image: python:3.8\\n          commands:\\n            - pip install -r requirements.txt\\n            - pytest\\n    - name: Deploy\\n      steps:\\n        - name: Deploy to GCP\\n          image: google/cloud-sdk:latest\\n          commands:\\n            - echo $GCLOUD_SERVICE_KEY | base64 --decode > ${HOME}/gcloud-service-key.json\\n            - gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json\\n            - gcloud config set project $GCP_PROJECT\\n            - gcloud app deploy\\n          environment:\\n            GCLOUD_SERVICE_KEY: <YOUR_BASE64_ENCODED_SERVICE_KEY>\\n            GCP_PROJECT: <YOUR_GCP_PROJECT_ID>\\n```\\n\\nI\\'ll update the pipeline accordingly.', 'role': 'assistant', 'function_call': None, 'tool_calls': [{'id': 'call_Rf6Q7AsyG3KeHVN5rksBmYG2', 'function': {'arguments': '{\"updated_pipeline_config\":\"pipeline:\\\\n  stages:\\\\n    - name: Lint\\\\n      steps:\\\\n        - name: Run Flake8\\\\n          image: python:3.8\\\\n          commands:\\\\n            - pip install flake8\\\\n            - flake8 .\\\\n    - name: Test\\\\n      steps:\\\\n        - name: Run Tests\\\\n          image: python:3.8\\\\n          commands:\\\\n            - pip install -r requirements.txt\\\\n            - pytest\\\\n    - name: Deploy\\\\n      steps:\\\\n        - name: Deploy to GCP\\\\n          image: google/cloud-sdk:latest\\\\n          commands:\\\\n            - echo $GCLOUD_SERVICE_KEY | base64 --decode > ${HOME}/gcloud-service-key.json\\\\n            - gcloud auth activate-service-account --key-file=${HOME}/gcloud-service-key.json\\\\n            - gcloud config set project $GCP_PROJECT\\\\n            - gcloud app deploy\\\\n          environment:\\\\n            GCLOUD_SERVICE_KEY: <YOUR_BASE64_ENCODED_SERVICE_KEY>\\\\n            GCP_PROJECT: <YOUR_GCP_PROJECT_ID>\"}', 'name': 'update_pipeline'}, 'type': 'function'}]}}\n",
      "Example 3 Response:\n",
      "{'response': {'content': \"The error indicates that the `environment` key should be a map, not a sequence (list). Here's the corrected YAML configuration:\\n```yaml\\npipeline:\\n  stages:\\n  - name: Build\\n    steps:\\n    - name: Build Image\\n      image: docker:latest\\n      commands:\\n        - docker build -t my-app .\\n        - docker push my-app:latest\\n      environment:\\n        DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}\\n        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}\\n```\\n\\nLet's update the pipeline configuration.\", 'role': 'assistant', 'function_call': None, 'tool_calls': [{'id': 'call_rArFeaNlLvXR56Lps7Kn0sY0', 'function': {'arguments': '{\"updated_pipeline_config\":\"pipeline:\\\\n  stages:\\\\n  - name: Build\\\\n    steps:\\\\n    - name: Build Image\\\\n      image: docker:latest\\\\n      commands:\\\\n        - docker build -t my-app .\\\\n        - docker push my-app:latest\\\\n      environment:\\\\n        DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}\\\\n        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}\"}', 'name': 'update_pipeline'}, 'type': 'function'}]}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Base URL for the FastAPI app\n",
    "base_url = \"http://localhost:8001\"\n",
    "\n",
    "# Example 1: Generate a CI/CD Pipeline Configuration\n",
    "def example_generate_pipeline():\n",
    "    url = f\"{base_url}/chat\"\n",
    "    payload = {\n",
    "        \"prompt\": \"Build python build pipeline\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Example 1 Response:\")\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "# Example 2: Update a CI/CD Pipeline Configuration\n",
    "def example_update_pipeline():\n",
    "    url = f\"{base_url}/chat\"\n",
    "    current_pipeline = \"\"\"\n",
    "    pipeline:\n",
    "      stages:\n",
    "        - name: Lint\n",
    "          steps:\n",
    "            - name: Run Flake8\n",
    "              image: python:3.8\n",
    "              commands:\n",
    "                - pip install flake8\n",
    "                - flake8 .\n",
    "        - name: Test\n",
    "          steps:\n",
    "            - name: Run Tests\n",
    "              image: python:3.8\n",
    "              commands:\n",
    "                - pip install -r requirements.txt\n",
    "                - pytest\n",
    "    \"\"\"\n",
    "    prompt = \"Add a stage for deploying to Google Cloud Platform (GCP) using the user's credentials. Update it for me.\"\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"extra_context\": [\n",
    "            {\n",
    "                \"description\": \"Current Pipeline\",\n",
    "                \"content\": current_pipeline\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Example 2 Response:\")\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "# Example 3: Analyze Failed Pipeline Logs and Suggest a Fix\n",
    "def example_fix_failed_pipeline():\n",
    "    url = f\"{base_url}/chat\"\n",
    "    logs = \"\"\"\n",
    "    Pipeline execution failed at stage 'Build'. Error parsing YAML configuration:\n",
    "    - name: Build\n",
    "      steps:\n",
    "        - name: Build Image\n",
    "          image: docker:latest\n",
    "          commands:\n",
    "            - docker build -t my-app .\n",
    "            - docker push my-app:latest\n",
    "          environment:\n",
    "          - DOCKER_PASSWORD=${{ secrets.DOCKER_PASSWORD }}\n",
    "          - DOCKER_USERNAME=${{ secrets.DOCKER_USERNAME }}\n",
    "    [ERROR] Invalid YAML format at line 6, column 7: 'environment' should be a map, but found a sequence instead.\n",
    "    \"\"\"\n",
    "    prompt = \"YAML configuration error: 'environment' should be a map, but found a sequence instead.\"\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"extra_context\": [\n",
    "            {\n",
    "                \"description\": \"Pipeline Logs\",\n",
    "                \"content\": logs\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Example 3 Response:\")\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "# Run examples\n",
    "if __name__ == \"__main__\":\n",
    "    example_generate_pipeline()\n",
    "    example_update_pipeline()\n",
    "    example_fix_failed_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
