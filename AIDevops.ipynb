{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "    go.mod\n",
      "    go.sum\n",
      "    README.md\n",
      "    package-lock.json\n",
      "    package.json\n",
      "    AIDevops.ipynb\n",
      "    dist/\n",
      "        schema.json\n",
      "    samples/\n",
      "        step-template.yaml\n",
      "        step.yaml\n",
      "        stage-group.yaml\n",
      "        step-approval.yaml\n",
      "        stage-runtime.yaml\n",
      "        failure-strategy-retry.yaml\n",
      "        step-background.yaml\n",
      "        pipeline-clone.yaml\n",
      "        step-run.yaml\n",
      "        pipeline-inputs.yaml\n",
      "        step-parallel.yaml\n",
      "        failure-strategy-manual.yaml\n",
      "        output.yaml\n",
      "        stage-template.yaml\n",
      "        step-run-test.yaml\n",
      "        matrix.yaml\n",
      "        step-queue.yaml\n",
      "        step-action.yaml\n",
      "        step-barrier.yaml\n",
      "        stage-volumes.yaml\n",
      "        pipeline-on.yaml\n",
      "        failure-strategy.yaml\n",
      "        pipeline-service.yaml\n",
      "        stage-caching.yaml\n",
      "        pipeline.yaml\n",
      "        stage-approval.yaml\n",
      "        environment.yaml\n",
      "        stage.yaml\n",
      "        step-group.yaml\n",
      "        stage-parallel.yaml\n",
      "        complex/\n",
      "            dynamic-provisioned-infra.yaml\n",
      "            kubernetes-canary.yaml\n",
      "            kubernetes-rolling.yaml\n",
      "            kubernetes-bluegreen.yaml\n",
      "            terraform-provisioning-adhoc.yaml\n",
      "        actions/\n",
      "            policy.yaml\n",
      "            wait.yaml\n",
      "            http.yaml\n",
      "            jira.yaml\n",
      "            helm-deploy.yaml\n",
      "            snow.yaml\n",
      "        templates/\n",
      "            npm.yaml\n",
      "    schema/\n",
      "        schema.ts\n",
      "        clone.ts\n",
      "        output.ts\n",
      "        status.ts\n",
      "        report.ts\n",
      "        repository.ts\n",
      "        workspace.ts\n",
      "        template.ts\n",
      "        permissions.ts\n",
      "        environment.ts\n",
      "        input.ts\n",
      "        pipeline.ts\n",
      "        failure.ts\n",
      "        platform.ts\n",
      "        container.ts\n",
      "        stages.ts\n",
      "        volumes.ts\n",
      "        runtime.ts\n",
      "        strategy.ts\n",
      "        cache.ts\n",
      "        concurrency.ts\n",
      "        on.ts\n",
      "        service.ts\n",
      "        steps.ts\n",
      "    approved/\n",
      "        k8s-delete.yaml\n",
      "        step.yaml\n",
      "        parallel-stage.yaml\n",
      "        kubernetes-blue-green.yaml\n",
      "        http.yaml\n",
      "        kubernetes-canary.yaml\n",
      "        wait-step.yaml\n",
      "        kubernetes-rolling.yaml\n",
      "        shell-script.yaml\n",
      "        matrix.yaml\n",
      "        failure-strategy.yaml\n",
      "        parallel-step.yaml\n",
      "        k8s-traffic-shift.yaml\n",
      "        pipeline.yaml\n",
      "        stage.yaml\n",
      "        step-group.yaml\n",
      "    scripts/\n",
      "        bundle.js\n",
      "        generate.js\n",
      "        generate2.js\n",
      "        document.js\n",
      "        templates/\n",
      "            enum.handlebars\n",
      "            custom_mount.handlebars\n",
      "            custom_action.handlebars\n",
      "            custom_volume.handlebars\n",
      "            parse.handlebars\n",
      "            custom_runtime.handlebars\n",
      "            custom_matrix.handlebars\n",
      "            struct_or_slice.handlebars\n",
      "            custom_on_schedule.handlebars\n",
      "            struct_or_string.handlebars\n",
      "            types.handlebars\n",
      "            custom_step.handlebars\n",
      "            custom_perms.handlebars\n",
      "            custom_environment.handlebars\n",
      "            custom_delegate.handlebars\n",
      "            struct.handlebars\n",
      "            parse_test.handlebars\n",
      "            custom_on.handlebars\n",
      "        helpers/\n",
      "            types.js\n",
      "    yaml/\n",
      "        volume_claim.go\n",
      "        step_queue.go\n",
      "        service_ref.go\n",
      "        credentials.go\n",
      "        environment_ref.go\n",
      "        clone_ref.go\n",
      "        service.go\n",
      "        strategy_matrix.go\n",
      "        runtime_vm.go\n",
      "        action.go\n",
      "        runtime.go\n",
      "        schema_infra.go\n",
      "        types.go\n",
      "        delegate.go\n",
      "        strategy.go\n",
      "        perms.go\n",
      "        stage_approval.go\n",
      "        stage_template.go\n",
      "        step_barrier.go\n",
      "        cache.go\n",
      "        environment_ref_item.go\n",
      "        parse_test.go\n",
      "        concurrency.go\n",
      "        action_type.go\n",
      "        on.go\n",
      "        runtime_cloud.go\n",
      "        environment_type.go\n",
      "        test_intelligence.go\n",
      "        template.go\n",
      "        environment.go\n",
      "        on_schedule.go\n",
      "        volume_bind.go\n",
      "        input.go\n",
      "        machine_size.go\n",
      "        pipeline.go\n",
      "        step_action.go\n",
      "        test_splitting.go\n",
      "        failure.go\n",
      "        action_retry.go\n",
      "        step_group.go\n",
      "        step.go\n",
      "        volume_temp.go\n",
      "        stage_group.go\n",
      "        runtime_kubernetes.go\n",
      "        volume.go\n",
      "        platform.go\n",
      "        report_list.go\n",
      "        container.go\n",
      "        failure_type.go\n",
      "        step_tester.go\n",
      "        schema.go\n",
      "        step_run.go\n",
      "        strategy_for.go\n",
      "        strategy_while.go\n",
      "        clone.go\n",
      "        status.go\n",
      "        machine_image.go\n",
      "        report.go\n",
      "        volume_config_map.go\n",
      "        action_manual.go\n",
      "        repository.go\n",
      "        step_approval.go\n",
      "        step_template.go\n",
      "        parse.go\n",
      "        workspace.go\n",
      "        stage.go\n",
      "        mount.go\n",
      "        credentials_aws.go\n",
      "        testdata/\n",
      "            sample.yaml.golden\n",
      "            sample.yaml\n",
      "        utils/\n",
      "            utils.go\n",
      "            expand/\n",
      "                expand_test.go\n",
      "                expand.go\n",
      "                testdata/\n",
      "                    step.yaml.golden\n",
      "                    step.yaml\n",
      "                    stage.yaml.golden\n",
      "                    stage.yaml\n",
      "                matrix/\n",
      "                    matrix.go\n",
      "            walk/\n",
      "                walk_test.go\n",
      "                walk.go\n",
      "            normalize/\n",
      "                namer_test.go\n",
      "                normalize.go\n",
      "                namer.go\n",
      "                normalize_test.go\n",
      "            github/\n",
      "                convert.go\n",
      "                convert_test.go\n",
      "            resolver/\n",
      "                resolver_test.go\n",
      "                resolver.go\n",
      "                testdata/\n",
      "                    step1.yaml.golden\n",
      "                    step2.yaml\n",
      "                    stage1.yaml.golden\n",
      "                    step2.yaml.golden\n",
      "                    stage1.yaml\n",
      "                    step1.yaml\n",
      "                    templates/\n",
      "                        golang.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        # Filter out directories and files starting with '.'\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        files = [f for f in files if not f.startswith('.')]\n",
    "        \n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "\n",
    "# Set the startpath to the current directory (repo root)\n",
    "startpath = '.'\n",
    "\n",
    "# Run the function\n",
    "list_files(startpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the OpenAI API key from environment variables\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "\n",
    "def gather_repo_context(folders):\n",
    "    context = \"\"\n",
    "    file_list = []\n",
    "    for folder in folders:\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            dirs[:] = [d for d in dirs if not d.startswith('.')]  # Exclude hidden directories\n",
    "            files = [f for f in files if not f.startswith('.')]  # Exclude hidden files\n",
    "            \n",
    "            for file in files:\n",
    "                if file.endswith(('.yaml', '.yml', '.ts', '.js', '.json', '.md', '.go')):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    file_list.append(file_path)\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        context += f\"\\n\\nFile: {file_path}\\n\" + f.read()\n",
    "    return context, file_list\n",
    "\n",
    "def create_messages(task, prompt, current_pipeline=None, logs=None, error_message=None, repo_context=\"\", secrets=None, user_info=None):\n",
    "    system_prompt = (\n",
    "        \"You are an AI programming assistant named 'AI Devops Engineer'. \"\n",
    "        \"You are part of a chat interface for an open source CI/CD platform called 'Gitness'. \"\n",
    "        \"Follow the user's requirements carefully & to the letter. \"\n",
    "        \"Your expertise is strictly limited to CI/CD and DevOps topics. \"\n",
    "        \"Follow Harness content policies. \"\n",
    "        \"Avoid content that violates copyrights. \"\n",
    "        \"For questions not related to CI/CD and DevOps, simply give a reminder that you are an AI Devops Engineer. \"\n",
    "        \"Keep your answers short and impersonal. \"\n",
    "        \"You can answer general DevOps questions and perform the following tasks through tool calls: \"\n",
    "        \"* Generate a CI/CD pipeline configuration \"\n",
    "        \"* Update a CI/CD pipeline configuration \"\n",
    "        \"* Analyze failed pipeline logs and suggest a code fix \"\n",
    "        \"First think step-by-step - describe your plan for what to build and then do it. \"\n",
    "        \"Minimize any other prose. \"\n",
    "        \"Avoid wrapping the whole response in triple backticks. \"\n",
    "        \"You can understand and use context from Gitness examples, JSON schema, and YAML files. \"\n",
    "        \"Each time you respond ensure the USER QUERY is satisfied to the best of your ability. \"\n",
    "        \"Make no assumptions about the functions and usage of YAML files that do not exist in the context, if there is missing information, ask for that information. \"\n",
    "        \"Do not make up an answer to questions that are not related to the query. \"\n",
    "        \"Prioritize using tool calls to perform the tasks when possible. \"\n",
    "        \"Do not explicitly mention the tool in the response. \"\n",
    "        \"There is no need to provide the full code or yaml in the message response unless specifically asked for. \"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"system\", \"content\": f\"Context from the repo: {repo_context}\"}\n",
    "    ]\n",
    "    \n",
    "    if secrets:\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"List of secrets: {secrets}\"})\n",
    "    \n",
    "    if user_info:\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"User information: {user_info}\"})\n",
    "    \n",
    "    if task == \"generate_pipeline\":\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    elif task == \"update_pipeline\":\n",
    "        if current_pipeline is None:\n",
    "            raise ValueError(\"current_pipeline must be provided for updating a pipeline.\")\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"The current pipeline configuration is:\\n{current_pipeline}\\n{prompt}\"})\n",
    "    elif task == \"fix_failed_pipeline\":\n",
    "        if logs is None or error_message is None:\n",
    "            raise ValueError(\"logs and error_message must be provided for analyzing a failed pipeline.\")\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"Analyze the following pipeline logs and error message to suggest a code fix:\\nLogs:\\n{logs}\\nError Message:\\n{error_message}\"})\n",
    "    else:\n",
    "        raise ValueError(\"Unknown task. Please provide a valid task: generate_pipeline, update_pipeline, or fix_failed_pipeline.\")\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def create_tools(task):\n",
    "    if task == \"generate_pipeline\":\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"generate_pipeline\",\n",
    "                    \"description\": \"Generates a CI/CD pipeline.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"pipeline_config\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The YAML configuration of the generated pipeline.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"pipeline_config\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    elif task == \"update_pipeline\":\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"update_pipeline\",\n",
    "                    \"description\": \"Updates a CI/CD pipeline\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"updated_pipeline_config\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The updated YAML configuration of the pipeline.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"updated_pipeline_config\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    elif task == \"fix_failed_pipeline\":\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"fix_failed_pipeline\",\n",
    "                    \"description\": \"Fix a failed pipeline.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"suggested_fix\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The suggested code fix based on the logs and error message.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"suggested_fix\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown task. Please provide a valid task: generate_pipeline, update_pipeline, or fix_failed_pipeline.\")\n",
    "    \n",
    "    return tools\n",
    "\n",
    "def call_openai_function(task, prompt, current_pipeline=None, logs=None, error_message=None, temperature=0.3, seed=42):\n",
    "    folders = ['./samples', './dist']  # List of folders to gather context from\n",
    "    repo_context, file_list = gather_repo_context(folders)\n",
    "\n",
    "    secrets = {\n",
    "        \"AWS_ACCESS_KEY_ID\": \"AKIA...\",\n",
    "        \"AWS_SECRET_ACCESS_KEY\": \"abc123...\",\n",
    "        \"DOCKER_PASSWORD\": \"s3cr3t...\"\n",
    "    }\n",
    "    \n",
    "    user_info = {\n",
    "        \"username\": \"johndoe\",\n",
    "        \"email\": \"johndoe@example.com\",\n",
    "        \"role\": \"developer\"\n",
    "    }\n",
    "    \n",
    "    messages = create_messages(task, prompt, current_pipeline, logs, error_message, repo_context, secrets, user_info)\n",
    "    tools = create_tools(task)\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        temperature=temperature,\n",
    "        user=\"userId\",  # https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids - not required, but recommended\n",
    "        seed=seed,\n",
    "        tool_choice=\"required\"\n",
    "\n",
    "    )\n",
    "\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        for tool_call in response.choices[0].message.tool_calls:\n",
    "            print(\"Made tool call:\")\n",
    "            print(f\"Tool Name: {tool_call.function.name}\")\n",
    "            print(f\"Arguments: {tool_call.function.arguments}\")\n",
    "    else:\n",
    "        print(\"No tool call made.\")\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made tool call:\n",
      "Tool Name: generate_pipeline\n",
      "Arguments: {\"pipeline_config\":\"pipeline:\\n  stages:\\n    - steps:\\n        - run:\\n            script: |\\n              python setup.py install\\n              python -m unittest discover\"}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Generate a CI/CD Pipeline Configuration\n",
    "task = \"generate_pipeline\"\n",
    "prompt = \"Build python build pipeline\"\n",
    "response = call_openai_function(task, prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made tool call:\n",
      "Tool Name: update_pipeline\n",
      "Arguments: {\"updated_pipeline_config\":\"pipeline:\\n  stages:\\n    - name: Lint\\n      steps:\\n        - name: Run Flake8\\n          image: python:3.8\\n          commands:\\n            - pip install flake8\\n            - flake8 .\\n    - name: Test\\n      steps:\\n        - name: Run Tests\\n          image: python:3.8\\n          commands:\\n            - pip install -r requirements.txt\\n            - pytest\\n    - name: Deploy\\n      steps:\\n        - name: Authenticate GCP\\n          image: google/cloud-sdk:latest\\n          commands:\\n            - echo $GOOGLE_APPLICATION_CREDENTIALS > /tmp/account.json\\n            - gcloud auth activate-service-account --key-file=/tmp/account.json\\n        - name: Deploy to GCP\\n          image: google/cloud-sdk:latest\\n          commands:\\n            - gcloud app deploy\"}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example 2: Update a CI/CD Pipeline Configuration\n",
    "task = \"update_pipeline\"\n",
    "current_pipeline = \"\"\"\n",
    "pipeline:\n",
    "  stages:\n",
    "    - name: Lint\n",
    "      steps:\n",
    "        - name: Run Flake8\n",
    "          image: python:3.8\n",
    "          commands:\n",
    "            - pip install flake8\n",
    "            - flake8 .\n",
    "    - name: Test\n",
    "      steps:\n",
    "        - name: Run Tests\n",
    "          image: python:3.8\n",
    "          commands:\n",
    "            - pip install -r requirements.txt\n",
    "            - pytest\n",
    "\"\"\"\n",
    "prompt = \"Add a stage for deploying to Google Cloud Platform (GCP) using the user's credentials. Update it for me.\"\n",
    "response = call_openai_function(task, prompt, current_pipeline=current_pipeline)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made tool call:\n",
      "Tool Name: fix_failed_pipeline\n",
      "Arguments: {\"suggested_fix\":\"Modify the 'environment' section to be a map instead of a sequence. Change:\\n  environment:\\n  - DOCKER_PASSWORD=${{ secrets.DOCKER_PASSWORD }}\\n  - DOCKER_USERNAME=${{ secrets.DOCKER_USERNAME }}\\nTo:\\n  environment:\\n    DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}\\n    DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}\"}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example 3: Analyze Failed Pipeline Logs and Suggest a Fix\n",
    "task = \"fix_failed_pipeline\"\n",
    "logs = \"\"\"\n",
    "Pipeline execution failed at stage 'Build'. Error parsing YAML configuration:\n",
    "- name: Build\n",
    "  steps:\n",
    "    - name: Build Image\n",
    "      image: docker:latest\n",
    "      commands:\n",
    "        - docker build -t my-app .\n",
    "        - docker push my-app:latest\n",
    "      environment:\n",
    "      - DOCKER_PASSWORD=${{ secrets.DOCKER_PASSWORD }}\n",
    "      - DOCKER_USERNAME=${{ secrets.DOCKER_USERNAME }}\n",
    "[ERROR] Invalid YAML format at line 6, column 7: 'environment' should be a map, but found a sequence instead.\n",
    "\"\"\"\n",
    "error_message = \"YAML configuration error: 'environment' should be a map, but found a sequence instead.\"\n",
    "\n",
    "response = call_openai_function(task, None, logs=logs, error_message=error_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders used as context:\n",
      "./samples\n",
      "./dist\n",
      "Made tool call:\n",
      "Tool Name: generate_pipeline\n",
      "Arguments: {\"pipeline_config\":\"pipeline:\\n  stages:\\n    - name: Build\\n      steps:\\n        - run:\\n            script: go build\\n    - name: DockerPush\\n      steps:\\n        - action:\\n            uses: docker-build-push-action\\n            with:\\n              push: true\\n              tags: latest\\n              repo: your-dockerhub-username/your-repo-name\"}\n",
      "--- Generated Pipeline ---\n",
      "\n",
      " Let's create a CI/CD pipeline that compiles your code and pushes the resulting Docker image to DockerHub.\n",
      "\n",
      "### Pseudocode\n",
      "1. Define the pipeline structure.\n",
      "2. Add a stage to compile the code.\n",
      "3. Add a stage to build and push the Docker image to DockerHub.\n",
      "\n",
      "### YAML Configuration\n",
      "```yaml\n",
      "pipeline:\n",
      "  stages:\n",
      "    - name: Build\n",
      "      steps:\n",
      "        - run:\n",
      "            script: go build\n",
      "    - name: DockerPush\n",
      "      steps:\n",
      "        - action:\n",
      "            uses: docker-build-push-action\n",
      "            with:\n",
      "              push: true\n",
      "              tags: latest\n",
      "              repo: your-dockerhub-username/your-repo-name\n",
      "```\n",
      "\n",
      "Now, I'll generate the pipeline using the provided function.\n",
      "Folders used as context:\n",
      "./samples\n",
      "./dist\n",
      "No tool call made.\n",
      "--- Updated Pipeline---\n",
      "\n",
      " Here's the updated pipeline configuration with a Slack notification step added:\n",
      "\n",
      "```yaml\n",
      "pipeline:\n",
      "  stages:\n",
      "  - steps:\n",
      "    - run:\n",
      "        script: go build\n",
      "    - action:\n",
      "        uses: slack-notify\n",
      "        with:\n",
      "          webhook-url: <your-slack-webhook-url>\n",
      "          message: \"Build completed successfully\"\n",
      "```\n",
      "\n",
      "Do you want me to update the pipeline with this configuration? If so, please provide the Slack webhook URL.\n",
      "Folders used as context:\n",
      "./samples\n",
      "./dist\n",
      "No tool call made.\n",
      "---Suggested Fix---\n",
      "\n",
      " Please provide the pipeline logs and the error message so I can analyze them and suggest a code fix.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "generate_prompt = \"Create a pipeline that compiles my code and pushes to DockerHub. Use the function provided.\"\n",
    "generate_response = call_openai_function(\"generate_pipeline\", generate_prompt)\n",
    "print(\"--- Generated Pipeline ---\\n\\n\", generate_response)\n",
    "\n",
    "current_pipeline = \"\"\"pipeline:\\n  stages:\\n  - steps:\\n    - run:\\n        script: go build\"\"\"  # Replace with the current pipeline configuration\n",
    "update_prompt = \"Add a Slack notification step to the pipeline.\"\n",
    "update_response = call_openai_function(\"update_pipeline\", update_prompt, current_pipeline=current_pipeline)\n",
    "print(\"--- Updated Pipeline---\\n\\n\", update_response)\n",
    "\n",
    "logs = \"\"\"...\"\"\"  # Replace with the pipeline logs\n",
    "error_message = \"\"\"...\"\"\"  # Replace with the error message\n",
    "analyze_response = call_openai_function(\"fix_failed_pipeline\", prompt=None, logs=logs, error_message=error_message)\n",
    "print(\"---Suggested Fix---\\n\\n\", analyze_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
